{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## encode functions\n",
    "##### main custom functions\n",
    "def one_hot_encode(df,columns_for_one_hot):\n",
    "    '''One hot encode the columns for feeding into the model\n",
    "    :df: Dataframe of the data\n",
    "    :columns_for_one_hot: array name of columns to input\n",
    "    :return: Dataframe of the one hot encoded data with prefix = columns_for_one_hot\n",
    "    '''\n",
    "#     for col_index in columns_for_one_hot:\n",
    "#         df[col_index]=df[col_index].replace(['0',0], 'No_{}'.format(col_index))\n",
    "    ## one hot encode\n",
    "    for column_for_one_hot in columns_for_one_hot:\n",
    "        #  Get one hot encoding of columns B\n",
    "        one_hot = pd.get_dummies(df[column_for_one_hot],prefix=column_for_one_hot)\n",
    "        # Drop column B as it is now encoded\n",
    "        df = df.drop(column_for_one_hot,axis = 1)\n",
    "        # Join the encoded df\n",
    "        df = df.join(one_hot,rsuffix=column_for_one_hot)\n",
    "    return df\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "def evaluate(y_pred,Y_val):\n",
    "    f1_sep=round(f1_score(Y_val, y_pred,average='micro'),6)\n",
    "    print('f1_score is:', str(f1_sep))\n",
    "    acc_sep=round(accuracy_score(Y_val, y_pred),6)\n",
    "    print('accuracy_score is:', str(acc_sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>temp1</th>\n",
       "      <th>temp10</th>\n",
       "      <th>temp11</th>\n",
       "      <th>temp12</th>\n",
       "      <th>temp13</th>\n",
       "      <th>temp14</th>\n",
       "      <th>temp15</th>\n",
       "      <th>temp16</th>\n",
       "      <th>temp17</th>\n",
       "      <th>...</th>\n",
       "      <th>area_Eastern France</th>\n",
       "      <th>area_Jura</th>\n",
       "      <th>area_Languedoc</th>\n",
       "      <th>area_Languedoc-Roussillon</th>\n",
       "      <th>area_Loire</th>\n",
       "      <th>area_Lyonnais</th>\n",
       "      <th>area_Provence</th>\n",
       "      <th>area_Rhône</th>\n",
       "      <th>area_Savoy</th>\n",
       "      <th>area_South West France</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>11.390</td>\n",
       "      <td>20.302</td>\n",
       "      <td>16.792</td>\n",
       "      <td>12.432</td>\n",
       "      <td>11.375</td>\n",
       "      <td>9.663</td>\n",
       "      <td>13.650</td>\n",
       "      <td>15.543</td>\n",
       "      <td>17.691</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.690</td>\n",
       "      <td>12.437</td>\n",
       "      <td>7.362</td>\n",
       "      <td>4.967</td>\n",
       "      <td>5.142</td>\n",
       "      <td>6.502</td>\n",
       "      <td>8.337</td>\n",
       "      <td>14.164</td>\n",
       "      <td>16.951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.350</td>\n",
       "      <td>11.176</td>\n",
       "      <td>7.606</td>\n",
       "      <td>3.811</td>\n",
       "      <td>2.580</td>\n",
       "      <td>4.904</td>\n",
       "      <td>7.617</td>\n",
       "      <td>9.347</td>\n",
       "      <td>12.848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>-1.763</td>\n",
       "      <td>10.034</td>\n",
       "      <td>3.674</td>\n",
       "      <td>1.283</td>\n",
       "      <td>-2.770</td>\n",
       "      <td>-4.096</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>6.836</td>\n",
       "      <td>16.905</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>4.761</td>\n",
       "      <td>10.858</td>\n",
       "      <td>5.631</td>\n",
       "      <td>2.999</td>\n",
       "      <td>4.350</td>\n",
       "      <td>4.755</td>\n",
       "      <td>5.160</td>\n",
       "      <td>9.238</td>\n",
       "      <td>11.430</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   temp1  temp10  temp11  temp12  temp13  temp14  temp15  temp16  \\\n",
       "0  2013  11.390  20.302  16.792  12.432  11.375   9.663  13.650  15.543   \n",
       "1  2011   4.690  12.437   7.362   4.967   5.142   6.502   8.337  14.164   \n",
       "2  2013   4.350  11.176   7.606   3.811   2.580   4.904   7.617   9.347   \n",
       "3  2013  -1.763  10.034   3.674   1.283  -2.770  -4.096  -0.363   6.836   \n",
       "4  2012   4.761  10.858   5.631   2.999   4.350   4.755   5.160   9.238   \n",
       "\n",
       "   temp17  ...  area_Eastern France  area_Jura  area_Languedoc  \\\n",
       "0  17.691  ...                    0          0               0   \n",
       "1  16.951  ...                    0          0               0   \n",
       "2  12.848  ...                    0          0               0   \n",
       "3  16.905  ...                    0          0               0   \n",
       "4  11.430  ...                    0          0               0   \n",
       "\n",
       "   area_Languedoc-Roussillon  area_Loire  area_Lyonnais  area_Provence  \\\n",
       "0                          0           0              0              1   \n",
       "1                          0           1              0              0   \n",
       "2                          0           0              0              0   \n",
       "3                          0           0              0              0   \n",
       "4                          0           0              0              0   \n",
       "\n",
       "   area_Rhône  area_Savoy  area_South West France  \n",
       "0           0           0                       0  \n",
       "1           0           0                       0  \n",
       "2           0           0                       0  \n",
       "3           0           0                       0  \n",
       "4           0           0                       0  \n",
       "\n",
       "[5 rows x 2538 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read and encode data\n",
    "dfg = pd.read_csv(\n",
    "    './vintage_wine_description_processed.csv',index_col=0).fillna(0)\n",
    "to_encode=['country','province','region_1','region_2','variety','area']\n",
    "to_drop=['designation','description','title','Location_description','location','winery','price','points']\n",
    "dfg=dfg.drop(to_drop,axis=1)\n",
    "dfg=one_hot_encode(dfg,to_encode)\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to categorical data\n",
    "for column_name in list(dfg.filter(regex='^(?:taste)').columns):\n",
    "    dfg[column_name]=pd.Categorical(dfg[column_name].apply(lambda x: 1 if x>0 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "taste_aroma      category\n",
       "taste_fruit      category\n",
       "taste_herb       category\n",
       "taste_palat      category\n",
       "taste_offer      category\n",
       "                   ...   \n",
       "taste_make       category\n",
       "taste_complex    category\n",
       "taste_power      category\n",
       "taste_delici     category\n",
       "taste_also       category\n",
       "Length: 98, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.filter(regex='^(?:taste)').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['taste_aroma', 'taste_fruit', 'taste_herb', 'taste_palat', 'taste_offer', 'taste_appl', 'taste_citru', 'taste_acid', 'taste_ripe', 'taste_fruiti', 'taste_smooth', 'taste_firm', 'taste_tannin', 'taste_juici', 'taste_red', 'taste_berri', 'taste_tart', 'taste_flavor', 'taste_lime', 'taste_green', 'taste_crisp', 'taste_lemon', 'taste_orang', 'taste_bit', 'taste_finish', 'taste_bottl', 'taste_come', 'taste_tannic', 'taste_earthi', 'taste_herbal', 'taste_good', 'taste_blackberri', 'taste_raspberri', 'taste_show', 'taste_mouth', 'taste_full', 'taste_bodi', 'taste_spici', 'taste_dark', 'taste_plum', 'taste_fresh', 'taste_bright', 'taste_white', 'taste_pepper', 'taste_savori', 'taste_balanc', 'taste_soft', 'taste_spice', 'taste_textur', 'taste_peach', 'taste_eleg', 'taste_pear', 'taste_touch', 'taste_cabernet', 'taste_merlot', 'taste_chocol', 'taste_miner', 'taste_charact', 'taste_layer', 'taste_rich', 'taste_black', 'taste_cherri', 'taste_oak', 'taste_vanilla', 'taste_style', 'taste_bake', 'taste_feel', 'taste_wood', 'taste_blend', 'taste_sauvignon', 'taste_toast', 'taste_currant', 'taste_pinot', 'taste_age', 'taste_licoric', 'taste_vineyard', 'taste_intens', 'taste_lead', 'taste_round', 'taste_sweet', 'taste_light', 'taste_clean', 'taste_made', 'taste_concentr', 'taste_grape', 'taste_one', 'taste_syrah', 'taste_tast', 'taste_long', 'taste_fine', 'taste_creami', 'taste_medium', 'taste_dens', 'taste_make', 'taste_complex', 'taste_power', 'taste_delici', 'taste_also']\n",
      "(125345, 2440) (125345, 98)\n",
      "Training Samples: (100276, 2440) (100276, 98)\n",
      "Validation Samples: (25069, 2440) (25069, 98)\n"
     ]
    }
   ],
   "source": [
    "### split xy and filter out columns that are not needed\n",
    "y_col=list(dfg.filter(regex='^(?:taste)').columns)\n",
    "# print(y_col)\n",
    "# regex_out_taste='^(?!taste)'\n",
    "X = dfg.drop(y_col, axis=1) # Training & Validation data\n",
    "Y = dfg[y_col]              # Response / Target Variable\n",
    "### normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "# Y=scaler.fit_transform(Y)\n",
    "# print(Y)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split training set so that we validate on 20% of the data\n",
    "# Note that our algorithms will never have seen the validation \n",
    "\n",
    "np.random.seed(5875) # set random seed for reproducibility\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = \\\n",
    "                train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print('Training Samples:', X_train.shape, Y_train.shape)\n",
    "print('Validation Samples:', X_val.shape, Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "lgbm = LGBMClassifier()           # create\n",
    "lgbm_regr= MultiOutputClassifier(lgbm)\n",
    "lgbm_regr.fit(X_train, Y_train.astype('int'))            # train\n",
    "y_pred=lgbm_regr.predict(X_val)\n",
    "evaluate(y_pred,Y_val.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "logreg = LogisticRegression(solver='newton-cg')           # create\n",
    "regr= MultiOutputClassifier(logreg)\n",
    "regr.fit(X_train, Y_train.astype('int'))            # train\n",
    "y_pred=regr.predict(X_val)\n",
    "evaluate(y_pred,Y_val.astype('int'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bays\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100276, 98)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-de4b87a3814e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-c612967bf995>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_pred, Y_val)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mf1_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f1_score is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_sep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0macc_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learnai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learnai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learnai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/learnai/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1253\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples']."
     ]
    }
   ],
   "source": [
    "y_pred=regr.predict(X_val)\n",
    "evaluate(y_pred,Y_val.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is: 0.293169\n",
      "accuracy_score is: 0.000199\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_pred,Y_val.astype('int'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
